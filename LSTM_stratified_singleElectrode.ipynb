{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835d2bb-83eb-4b29-a82f-ce706527b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_el = joblib.load('it.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83689ba7-99ed-4630-b536-60873244b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur_el = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e6358-8b9d-42f1-8b34-cee694ab7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path('C:/Users/ilkele4s/')\n",
    "\n",
    "main_results_folder = Path('ML_Results/LSTM_stratified_singleElectrode_results')\n",
    "new_results_folder = 'electrode_' +str(cur_el)\n",
    "\n",
    "data_folder = Path('Data/Electrodes')\n",
    "data_file = 'electrode_' +str(cur_el) + '.csv'\n",
    "\n",
    "tune_folder = 'Tune'\n",
    "project_name = 'Random_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a8cb9-e125-4085-9eef-cd681b4f7084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = os.path.join(base_folder,main_results_folder)\n",
    "\n",
    "#if cur_el == 1:\n",
    "#    os.mkdir(results_dir)\n",
    "\n",
    "new_results_dir = os.path.join(results_dir,new_results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806de05-bbca-4206-96e8-1a1b82b66aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(new_results_dir)\n",
    "\n",
    "print(new_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1d064-2560-43c9-8d7f-8a8302db4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_dir = os.path.join(new_results_dir,tune_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257977ca-4345-46b7-90e0-0ea21286f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "data_dir = os.path.join(base_folder,data_folder)\n",
    "\n",
    "data_file_path = os.path.join(data_dir,data_file)\n",
    "\n",
    "print(data_file_path)\n",
    "\n",
    "Data = pd.read_csv(data_file_path, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb8d9a-c2f1-42ad-8dd1-ca7943d4ac9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structure samples for LSTM\n",
    "\n",
    "data_array = np.array(Data)\n",
    "\n",
    "n_samples = data_array.shape[0]\n",
    "n_features = data_array.shape[1]\n",
    "\n",
    "bin_cur = 1\n",
    "bin_past = 3\n",
    "\n",
    "bins_predict = bin_cur + bin_past # 3 previous + 1 current\n",
    "\n",
    "formatted_data = np.zeros([n_samples,bins_predict,n_features])\n",
    "\n",
    "start_idx=0\n",
    "for i in range(n_samples-bin_past):\n",
    "    end_idx=start_idx+bins_predict # indices for 4 elements (sliding fashion)\n",
    "    formatted_data[i+bin_past,:,:]=data_array[start_idx:end_idx,:] # indexing the data with indices from the previous step\n",
    "    start_idx=start_idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accea84f-1fd9-45f4-b3e7-100392dafd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data[np.isnan(formatted_data)] = 0 # replacing nans with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785ad7a-9031-4bed-a76c-4324447d1384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a label set\n",
    "\n",
    "n_zones = 45\n",
    "n_trials = 32\n",
    "\n",
    "## one-hot-encoding \n",
    "cat_zones = keras.utils.to_categorical(np.r_[1:n_zones+1] ,num_classes=46) # one-hot-encoding \n",
    "cat_zones = np.delete(cat_zones,0,1)\n",
    "\n",
    "## repeating the labels for 32 (no_of trial) times\n",
    "labels_all_trials = np.tile(cat_zones, 32) \n",
    "\n",
    "\n",
    "## reshaping the data from  (45,1440) to (1440,45)\n",
    "reshaped_labels_all_trials = np.reshape(labels_all_trials, [n_samples, 45])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776634d-568d-407b-9047-fc5e7844b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first train - test split -- STRATIFIED\n",
    "\n",
    "## later train will be splitted into train - validation\n",
    "## we aim for 60 - 20 - 20 \n",
    "\n",
    "train_samples, test_samples, train_labels, test_labels = train_test_split(formatted_data, reshaped_labels_all_trials,\n",
    "                                                                          test_size=.20, \n",
    "                                                                          stratify=reshaped_labels_all_trials, \n",
    "                                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b70c44-28a7-496d-8361-c2a8c30c38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the split size for the second split to achive aimed ratios\n",
    "\n",
    "train_size = np.shape(train_samples)\n",
    "test_size = np.shape(test_samples)\n",
    "split_size =1/(train_size[0]/ test_size[0])\n",
    "#print(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8c75c-8fb3-4b61-8625-8979e9367409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - validation split -- STRATIFIED\n",
    "\n",
    "train_samples, validation_samples, train_labels, validation_labels, = train_test_split(train_samples, train_labels, \n",
    "                                                                                       test_size=.25, \n",
    "                                                                                       stratify=train_labels, \n",
    "                                                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9744d-67b3-4feb-aa88-114a727168d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(train_samples, os.path.join(new_results_dir,'train_samples.sav'))\n",
    "joblib.dump(train_labels, os.path.join(new_results_dir,'train_labels.sav'))\n",
    "\n",
    "joblib.dump(test_samples, os.path.join(new_results_dir,'test_samples.sav'))\n",
    "joblib.dump(test_labels, os.path.join(new_results_dir,'test_labels.sav'))\n",
    "\n",
    "joblib.dump(validation_samples, os.path.join(new_results_dir,'validation_samples.sav'))\n",
    "joblib.dump(validation_labels, os.path.join(new_results_dir,'validation_labels.sav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003312a-70f6-4bcd-b865-cc8eef9bd42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    \n",
    "    ## in which stage the parameter is defined e.g, no of units in build, shuffle in fit\n",
    "\n",
    "    def build(self,hp): # defining a build function with specifics of no of layers, type of layer, optimizer, activation functions\n",
    "        \n",
    "            ## creating the search space\n",
    "        \n",
    "            LSTM_units = [30, 40] # no of LSTM units\n",
    "            Drop_rate = [.20, .30, .40] # no of Drop rate\n",
    "            RecDrop_rate = [.20, .30, .40] # no of Recurrent drop rate\n",
    "            learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling=\"log\") # learning rate\n",
    "\n",
    "            model=Sequential()\n",
    "            model.add(Masking(mask_value=0, input_shape=(4, n_features))),  # n_features = 300\n",
    "            model.add(LSTM(hp.Choice('LSTM_units',LSTM_units), # choice --> choosing sth from the list               \n",
    "                           input_shape=(4, n_features), \n",
    "                           dropout=hp.Choice('Drop_rate',Drop_rate),\n",
    "                           recurrent_dropout=hp.Choice('RecDrop_rate', RecDrop_rate)))\n",
    "\n",
    "            model.add(Dense(45, activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "                          ,metrics=['accuracy'])\n",
    "\n",
    "            return model \n",
    "        \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            #  whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e49eb-60e7-48c8-8faa-e9091206c64f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tuner = kt.GridSearch(\n",
    "#    MyHyperModel(),\n",
    "#    objective =kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "#    overwrite=True,\n",
    "#    directory=tune_dir ,\n",
    "#    project_name=project_name,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b6561-76c8-4827-a11f-1407be09e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search tuner\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective =kt.Objective(\"val_loss\", direction=\"min\"), # optimize for minimizing validation loss\n",
    "    overwrite=True, # overwrite the previous results in the same directory\n",
    "    max_trials=30, # max trials to randomly select parameter values (The total number of trials to run during the search)\n",
    "    directory= tune_dir , \n",
    "    project_name=project_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb55728-ed59-479c-a664-500a3c3f065c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.search(train_samples, train_labels, epochs=30, validation_data=(validation_samples, validation_labels),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1bf2e-2a43-463c-8277-fbf89b1cd8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the best three trials in a txt file\n",
    "\n",
    "## Capture the printed output using io.StringIO\n",
    "summary_output = io.StringIO()\n",
    "\n",
    "## Use contextlib.redirect_stdout to redirect the print output to the StringIO object\n",
    "with contextlib.redirect_stdout(summary_output):\n",
    "    tuner.results_summary(num_trials=3)\n",
    "\n",
    "## Get the captured output\n",
    "summary_text = summary_output.getvalue()\n",
    "\n",
    "file = open(os.path.join(new_results_dir,'best_3params.txt'), 'w')\n",
    "# Write content to the file\n",
    "file.write(summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47802e75-c0e2-4560-a643-8eea275c2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing parameter values\n",
    "best_hp = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ff4c8-1abb-4691-9c93-e7ea1ba0b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best performing parameter values\n",
    "joblib.dump(best_hp, os.path.join(new_results_dir,'best_hyperparameters.sav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab66b7-47ca-48f2-aef6-a7a00b80144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyHyperModel()\n",
    "\n",
    "# building the model\n",
    "best_model = model.build(best_hp)\n",
    "\n",
    "# training the model\n",
    "best_model_trained = model.fit(best_hp, best_model, train_samples, \n",
    "                               train_labels,validation_data=(validation_samples, validation_labels), epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1523a-9348-4c31-9009-748979954ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trial folders from the tunning \n",
    "\n",
    "## Define a pattern to match files with names like \"trial1\", \"trial2\", etc.\n",
    "\n",
    "to_remove = os.path.join(tune_dir, project_name)\n",
    "pattern = \"trial*\"\n",
    "\n",
    "## Use glob to find matching files\n",
    "matching_files = glob.glob(os.path.join(to_remove, pattern))\n",
    "\n",
    "## Iterate over matching files and delete them\n",
    "for file_path in matching_files:\n",
    "    try:\n",
    "        shutil.rmtree(file_path)\n",
    "        #print(f\"File '{file_path}' deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting '{file_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f069d-211b-486d-bd5a-2bd189971038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(best_model_trained.history['loss'])\n",
    "plt.plot(best_model_trained.history['val_loss'])\n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "ay = plt.gca()\n",
    "\n",
    "ay.yaxis.set_major_locator(MultipleLocator(base=0.50)) \n",
    "\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig(os.path.join(new_results_dir,'Model_loss.png'))\n",
    "#plt.show()\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb3cd5-3401-4def-86a9-771bdf0f255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_model_trained.history['accuracy'])\n",
    "plt.plot(best_model_trained.history['val_accuracy'])\n",
    "\n",
    "\n",
    "ay = plt.gca()\n",
    "ay.yaxis.set_major_locator(MultipleLocator(base=0.10)) \n",
    "\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig(os.path.join(new_results_dir,'Model_accuracy.png'))\n",
    "#plt.show()\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631637f-f8b2-4456-8d5e-dacb8002dac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = best_model.predict(test_samples)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=1) + 1\n",
    "\n",
    "true_label = np.argmax(test_labels, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7aa4d-64a2-44c0-8860-b94e795c5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(predictions, os.path.join(new_results_dir,'predictions.sav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8028dc-fa4c-4e24-8ce3-127b4d0bd798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(true_label, predicted_labels, normalize='true')\n",
    "\n",
    "class_labels = [str(i) for i in range(1, 46)]\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(cm, fmt='.2',annot=True, annot_kws={\"size\": 8}, xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig(os.path.join(new_results_dir,'Cm_optim.png'))\n",
    "plt.show()\n",
    "#plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d90002-0d85-4a69-89c3-f5b8c121f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_label, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad159798-7c6e-419f-82c0-e974fb2e1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = report['weighted avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d9cc3-b1cc-45a8-9883-c658f4bc562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(new_results_dir,'F1.txt'), 'w')\n",
    "# Write content to the file\n",
    "file.write(str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dec7a5-a511-4663-aa89-e1abfe76ef01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Acc = balanced_accuracy_score(true_label, predicted_labels)\n",
    "print('Weighted accuracy is:', Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35835d1d-d876-42ac-a74e-121b82f4bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(new_results_dir,'Acc_balanced.txt'), 'w')\n",
    "# Write content to the file\n",
    "file.write(str(Acc))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36412fbd-b586-41d1-bc34-36e8a860b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the CSV file\n",
    "csv_filename = 'All_singleElec_accuracies.csv'\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_filename, 'a', newline='') as csv_file:\n",
    "    # Create a CSV writer\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write the number to a new row\n",
    "    csv_writer.writerow([Acc])\n",
    "    \n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
